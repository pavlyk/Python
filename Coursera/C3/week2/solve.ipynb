{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "48\n1\n6\n10\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import unittest\n",
    "import re\n",
    "\n",
    "def parse(path_to_file):    \n",
    "    # Поместите ваш код здесь.\n",
    "    # ВАЖНО!!!\n",
    "    # При открытии файла, добавьте в функцию open необязательный параметр\n",
    "    # encoding='utf-8', его отсутствие в коде будет вызвать падение вашего\n",
    "    # решения на грейдере с ошибкой UnicodeDecodeError\n",
    "    with open(path_to_file, encoding='utf-8') as data:\n",
    "        soup = BeautifulSoup(data, \"html.parser\")\n",
    "\n",
    "    body = soup.find(id=\"bodyContent\")\n",
    "    lenimgs = len([x for x in body.find_all('img') if int(x.get('width')) >= 20])\n",
    "    lenHeads = len([x.text for x in body.find_all(re.compile(r'h\\d+')) if x.text[0] in ['E','T','C']])\n",
    "    lenlink = 0\n",
    "    all_links = body.find_all('a')\n",
    "    for link in all_links:\n",
    "        current_count = 1\n",
    "        siblings = link.find_next_siblings()\n",
    "        for sibling in siblings:\n",
    "            if sibling.name == 'a':\n",
    "                current_count += 1\n",
    "                lenlink = max(current_count, max_count)\n",
    "            else:\n",
    "                current_count = 0\n",
    "    lenlists = 0\n",
    "    all_lists = body.find_all(['ul', 'ol'])\n",
    "    for tag in all_lists:\n",
    "        if not tag.find_parents(['ul', 'ol']):\n",
    "            lenlists += 1\n",
    "    return [lenimgs, lenHeads, lenlink, lenlists]\n",
    "\n",
    "\n",
    "parse('wiki/14th_Chess_Olympiad')\n",
    "\n",
    "\n",
    "# class TestParse(unittest.TestCase):\n",
    "#     def test_parse(self):\n",
    "#         test_cases = (\n",
    "#             ('wiki/Stone_Age', [13, 10, 12, 40]),\n",
    "#             ('wiki/Brain', [19, 5, 25, 11]),\n",
    "#             ('wiki/Artificial_intelligence', [8, 19, 13, 198]),\n",
    "#             ('wiki/Python_(programming_language)', [2, 5, 17, 41]),\n",
    "#             ('wiki/Spectrogram', [1, 2, 4, 7]),)\n",
    "\n",
    "#         for path, expected in test_cases:\n",
    "#             with self.subTest(path=path, expected=expected):\n",
    "#                 self.assertEqual(parse(path), expected)\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     unittest.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}